{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1518243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbdb13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectAndDescribe(method=None):    \n",
    "    if method == 'sift':\n",
    "        descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "    elif method == 'surf':\n",
    "        descriptor = cv2.xfeatures2d.SURF_create()\n",
    "    elif method == 'orb':\n",
    "        descriptor = cv2.ORB_create()\n",
    "        \n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63574f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatcher(method):\n",
    "    if method == \"BruteForce\":\n",
    "        matcher = cv2.DescriptorMatcher_create(\"BruteForce\")\n",
    "    elif method == \"FLANN\":\n",
    "        matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)\n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69ed310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitcher(img1,img2,desc = None, mat = None):\n",
    "    descriptor = detectAndDescribe(desc)\n",
    "    (kps1, features1) = descriptor.detectAndCompute(img1, None)\n",
    "    (kps2, features2) = descriptor.detectAndCompute(img2, None)\n",
    "\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    \n",
    "    matcher = createMatcher(mat)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    # Compute the matches\n",
    "    matches = flann.knnMatch(features1, features2, k=2)\n",
    "    \n",
    "    # Store all the good matches as per Lowe's ratio test\n",
    "    good_matches = []\n",
    "    for m1,m2 in matches:\n",
    "        if m1.distance < 0.7*m2.distance:\n",
    "            good_matches.append(m1)\n",
    "            \n",
    "    if len(good_matches) > 10:\n",
    "        src_pts = np.float32([ keypoints1[good_match.queryIdx].pt\n",
    "                              for good_match in good_matches ]).reshape(-1,1,2)\n",
    "        \n",
    "        dst_pts = np.float32([ keypoints2[good_match.trainIdx].pt \n",
    "                              for good_match in good_matches ]).reshape(-1,1,2)\n",
    "        \n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        result = warpImages(img2, img1, M)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b853a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('uni_test_1.jpg')\n",
    "img2 = cv2.imread('uni_test_2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7d7a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpImages(img1, img2, H):\n",
    "    rows1, cols1 = img1.shape[:2]\n",
    "    rows2, cols2 = img2.shape[:2]\n",
    "    \n",
    "    list_of_points_1 = np.float32([\n",
    "        [0,0], \n",
    "        [0,rows1],\n",
    "        [cols1,rows1], \n",
    "        [cols1,0]\n",
    "    ])\n",
    "    list_of_points_1 = list_of_points_1.reshape(-1,1,2)\n",
    "\n",
    "    temp_points = np.float32([\n",
    "        [0,0], \n",
    "        [0,rows2], \n",
    "        [cols2,rows2],\n",
    "        [cols2,0]\n",
    "    ])\n",
    "    temp_points = temp_points.reshape(-1,1,2)\n",
    "    \n",
    "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
    "    \n",
    "    list_of_points = np.concatenate((list_of_points_1, list_of_points_2), axis=0)\n",
    "    \n",
    "    ##Define boundaries:\n",
    "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
    "    \n",
    "    translation_dist = [-x_min,-y_min]\n",
    "    \n",
    "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0,0,1]])\n",
    "    \n",
    "    output_img = cv2.warpPerspective(img2, \n",
    "                                     H_translation.dot(H), \n",
    "                                     (x_max - x_min, y_max - y_min))\n",
    "    ## Paste the image:\n",
    "    output_img[translation_dist[1]:rows1+translation_dist[1], \n",
    "               translation_dist[0]:cols1+translation_dist[0]] = img1\n",
    "    \n",
    "    return output_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a31dcd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "images.append(img1)\n",
    "images.append(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce1c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pano = stitcher(img1, img2,desc = 'sift', mat = \"FLANN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ff6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
